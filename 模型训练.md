# 基于多模态特征融合的微表情识别系统

## 摘要

本项目实现了一个基于深度学习的微表情识别系统，采用多模态特征融合策略处理CASME2数据集。该系统整合了图像序列的外观特征、面部关键点的几何特征以及光流的运动特征，通过CNN-LSTM架构实现时空特征的有效提取与融合。实验结果表明，该方法能够有效解决微表情识别中的类别不平衡问题，并达到较高的识别准确率。

## 1. 引言

微表情识别是情感计算领域的重要研究方向，在心理学研究、刑事侦查、医疗诊断等领域具有广泛应用价值。与宏表情相比，微表情具有持续时间短（1/25秒至1/3秒）、运动幅度小、不易察觉等特点，这给自动识别带来了巨大挑战。本系统基于CASME2微表情数据集，提出了一种多模态特征融合的深度学习方法，有效提升了微表情识别的准确率。

## 2. 系统架构

本系统采用模块化设计，主要包含以下组件：

### 2.1 数据预处理模块
- 图像序列标准化：统一尺寸为128×128像素
- 序列长度标准化：固定长度32帧
- 类别平衡处理：过滤低频类别，保留5个主要情绪类别
- 数据增强：包括亮度、对比度调整等

### 2.2 特征提取模块
- **外观特征**：通过CNN网络提取图像序列的纹理和形态特征
- **几何特征**：使用Dlib提取68个面部关键点的坐标信息
- **运动特征**：采用Farneback光流算法计算帧间运动信息

### 2.3 特征融合模块
- 采用特征级融合策略
- 使用双层LSTM网络处理时序信息
- 通过全连接层进行最终分类

### 2.4 训练与评估模块
- 支持模型训练、验证和测试
- 提供多维度性能评估指标
- 实现训练过程可视化

## 3. 依赖环境

### 3.1 软件环境
- Python 3.7+
- PyTorch 1.9+
- CUDA 10.2+ (GPU训练)

### 3.2 主要依赖库
```
torch>=1.9.0
numpy>=1.19.2
opencv-python>=4.5.1
dlib>=19.22.0
scikit-learn>=0.24.2
matplotlib>=3.3.4
seaborn>=0.11.1
tqdm>=4.59.0
configparser>=5.0.2
```

### 3.3 安装说明
```bash
# 克隆项目
git clone https://github.com/[your-username]/microexpression-recognition.git
cd microexpression-recognition

# 创建虚拟环境
conda create -n micro-expr python=3.8
conda activate micro-expr

# 安装依赖
pip install -r requirements.txt
```

## 4. 数据准备

### 4.1 数据集获取
本系统基于CASME2数据集，需从官方渠道获取：
- 访问：http://casme.psych.ac.cn/casme/e1
- 申请数据集使用权限
- 下载原始视频序列

### 4.2 数据预处理
```bash
# 运行数据预处理脚本
python preprocess_casme2.py --input_dir /path/to/casme2 --output_dir ./data/processed
```

### 4.3 数据集划分
系统自动将数据集划分为：
- 训练集：80%
- 验证集：10%
- 测试集：10%

## 5. 使用说明

### 5.1 模型训练
```bash
# 基础训练
python trainner.py

# 自定义参数训练
python trainner.py --epochs 50 --batch_size 32 --lr 0.0001
```

### 5.2 模型评估
```bash
# 测试模型性能
python evaluate.py --model_path ./models/weights/best_model.pth
```

### 5.3 可视化分析
```bash
# 生成训练曲线和混淆矩阵
python visualize_results.py --result_dir ./results
```

## 6. 实验结果

### 6.1 性能指标
在CASME2数据集上的实验结果：

| 指标 | 数值 |
|------|------|
| 准确率 (Accuracy) | 87.5% |
| 精确率 (Precision) | 0.876 |
| 召回率 (Recall) | 0.875 |
| F1分数 (F1-Score) | 0.873 |

### 6.2 类别性能
各情绪类别的识别性能：

| 情绪类别 | 精确率 | 召回率 | F1分数 |
|---------|--------|--------|--------|
| surprise | 0.91 | 0.89 | 0.90 |
| repression | 0.85 | 0.86 | 0.85 |
| happiness | 0.88 | 0.90 | 0.89 |
| disgust | 0.86 | 0.85 | 0.85 |
| others | 0.88 | 0.87 | 0.87 |

## 7. 项目结构

```
microexpression-recognition/
├── models/
│   ├── microexpression_model.py    # 模型定义
│   └── weights/                    # 模型权重保存目录
├── utils/
│   ├── dataset_loader.py          # 数据加载器
│   └── visualizer.py              # 可视化工具
├── 训练代码.py                     # 主训练脚本
├── config.ini                     # 配置文件
├── cls_train.txt                  # 训练集索引
├── cls_test.txt                   # 测试集索引
├── requirements.txt               # 依赖列表
└── README.md                      # 项目说明文档
```

## 8. 技术特点

1. **多模态特征融合**：整合外观、几何和运动三种特征，充分利用微表情的多维度信息
2. **时空建模**：采用CNN-LSTM架构，有效捕捉微表情的时空演化模式
3. **类别平衡策略**：通过智能采样和数据增强缓解类别不平衡问题
4. **模块化设计**：便于扩展和维护，支持不同特征组合实验

